{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220317_ji_target2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeongname/jeongname/blob/main/220329_hj_Koelectra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JZAGLg1GguD",
        "outputId": "74d1fdc4-2f2a-4397-96de-88d217c068d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-optimizer"
      ],
      "metadata": {
        "id": "16t_m2HFXrqC",
        "outputId": "8a242b01-adc4-4473-e70b-5154d766613d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-optimizer in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch-optimizer) (1.10.0+cu111)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch-optimizer) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch-optimizer) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% pip install sentencepiece"
      ],
      "metadata": {
        "id": "bh5b9EQAZPTo",
        "outputId": "6a8cbfad-b66f-4817-b7b4-e112d5734f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 9.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ LIBRARY -------#\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import pandas as pd\n",
        "import re\n",
        "import cv2\n",
        "# torch\n",
        "import torch\n",
        "import torch.cuda.amp as amp\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import *\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, MultiStepLR, OneCycleLR\n",
        "#\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import torch_optimizer as optim\n",
        "from collections import defaultdict\n",
        "import itertools as it\n",
        "\n",
        "import tqdm\n",
        "import random\n",
        "#import time\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "# transformer\n",
        "from transformers import XLMPreTrainedModel, XLMRobertaModel, XLMRobertaConfig, XLMRobertaTokenizer\n",
        "from transformers import XLMRobertaForSequenceClassification, BertForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertForSequenceClassification, DistilBertForSequenceClassification, XLNetForSequenceClassification,\\\n",
        "XLMRobertaForSequenceClassification, XLMForSequenceClassification, RobertaForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "QHAe7WC2XiZs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/SANUP/1. 실습용자료.txt', sep='|', encoding='cp949')\n",
        "test = pd.read_csv('/content/drive/MyDrive/SANUP/2. 모델개발용자료.txt', sep='|', encoding='cp949')"
      ],
      "metadata": {
        "id": "EZAZmPKdG8IM"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class args\n",
        "class args:\n",
        "    # ---- factor ---- #\n",
        "    debug=False\n",
        "    amp = True\n",
        "    gpu = '0'\n",
        "    \n",
        "    epochs=10\n",
        "    batch_size=1\n",
        "    weight_decay=1e-6\n",
        "    n_fold=5\n",
        "    fold=3 # [0, 1, 2, 3, 4] # 원래는 3\n",
        "    \n",
        "    exp_name = 'experiment_name_folder'\n",
        "    dir_ = f'./saved_models/'\n",
        "    pt = 'your_model_name'\n",
        "    max_len = 33\n",
        "    \n",
        "    start_lr = 1e-5#1e-3,5e-5\n",
        "    min_lr=1e-6\n",
        "    # ---- Dataset ---- #\n",
        "\n",
        "    # ---- Else ---- #\n",
        "    num_workers=8\n",
        "    seed=2021\n",
        "    scheduler = None#'get_linear_schedule_with_warmup'\n",
        "\n",
        "\n",
        "data_dir = './'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "##----------------\n",
        "def set_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False # for faster training, but not deterministic\n",
        "\n",
        "set_seeds(seed=args.seed)    "
      ],
      "metadata": {
        "id": "VxmvwVXrYANx"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - util - #\n",
        "def get_learning_rate(optimizer):\n",
        "    lr=[]\n",
        "    for param_group in optimizer.param_groups:\n",
        "        lr +=[ param_group['lr'] ]\n",
        "\n",
        "    assert(len(lr)==1) #we support only one param_group\n",
        "    lr = lr[0]\n",
        "\n",
        "    return lr\n",
        "\n",
        "def load_data():\n",
        "    train = pd.read_csv('/content/drive/MyDrive/SANUP/1. 실습용자료.txt', sep='|', encoding='cp949')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/SANUP/2. 모델개발용자료.txt', sep='|', encoding='cp949')\n",
        "\n",
        "    train = train.fillna(\" \")\n",
        "\n",
        "    train = train[train['digit_1']==\"C\"].copy().reset_index(drop=True)\n",
        "\n",
        "    train['target'] = train['digit_2']\n",
        "    train[\"text\"] = train[\"text_obj\"]+ \" \" + train[\"text_mthd\"] + \" \" + train[\"text_deal\"]\n",
        "\n",
        "    train['text'] = train['text'].str.strip()\n",
        "\n",
        "    train['No.']=train.index\n",
        "\n",
        "    train=train[['text','target']]\n",
        "\n",
        "    test[\"text\"] = test[\"text_obj\"]+ \" \" + test[\"text_mthd\"] + \" \" + test[\"text_deal\"]\n",
        "\n",
        "    test['text'] = test['text'].str.strip()\n",
        "    \n",
        "    #\n",
        "    train = train[['text','target']]\n",
        "    test=test[['text']]\n",
        "    #\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "    train['fold'] = -1\n",
        "    for n_fold, (_,v_idx) in enumerate(skf.split(train, train['target'])):\n",
        "        train.loc[v_idx, 'fold']  = n_fold\n",
        "    train['id'] = [x for x in range(len(train))]\n",
        "    \n",
        "    return train, test"
      ],
      "metadata": {
        "id": "PtacL8XFYDW5"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make KoBertTokenizer\n",
        "import logging\n",
        "import os\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        " \n",
        "from transformers import PreTrainedTokenizer\n",
        " \n",
        "logger = logging.getLogger(__name__)\n",
        " \n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\n",
        " \n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
        "    }\n",
        "}\n",
        " \n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512,\n",
        "    \"monologg/kobert-lm\": 512,\n",
        "    \"monologg/distilkobert\": 512\n",
        "}\n",
        " \n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
        "}\n",
        " \n",
        "SPIECE_UNDERLINE = u'▁'\n",
        " \n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "        SentencePiece based tokenizer. Peculiarities:\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        " \n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_file,\n",
        "            vocab_txt,\n",
        "            do_lower_case=False,\n",
        "            remove_space=True,\n",
        "            keep_accents=False,\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs\n",
        "        )\n",
        " \n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        " \n",
        "        #self.max_len_single_sentence = self.max_len - 2  # take into account special tokens\n",
        "        #self.max_len_sentences_pair = self.max_len - 3  # take into account special tokens\n",
        " \n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        " \n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        " \n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        " \n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        " \n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        " \n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        " \n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        " \n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        " \n",
        "        return outputs\n",
        " \n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
        "        \"\"\" Tokenize a string. \"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        " \n",
        "        if not sample:\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\n",
        "        else:\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        " \n",
        "        return new_pieces\n",
        " \n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        " \n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        " \n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        " \n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A RoBERTa sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        " \n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        " \n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        " \n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        " \n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A BERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        " \n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "            to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        " \n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        " \n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        " \n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        " \n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "metadata": {
        "id": "3xKfKtZ5YnT2"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_tokenizer(sent, MAX_LEN, tokenizer):\n",
        "    \n",
        "    encoded_dict=tokenizer.encode_plus(\n",
        "    text = sent, \n",
        "    add_special_tokens=True, \n",
        "    max_length=MAX_LEN, \n",
        "    pad_to_max_length=True, \n",
        "    return_attention_mask=True,\n",
        "    truncation = True)\n",
        "    \n",
        "    input_id=encoded_dict['input_ids']\n",
        "    attention_mask=encoded_dict['attention_mask']\n",
        "    #token_type_id = encoded_dict['token_type_ids']\n",
        "    token_type_id = 0\n",
        "    \n",
        "    return input_id, attention_mask, token_type_id\n",
        "\n",
        "def preprocessing_train():\n",
        "    \n",
        "    pt = args.pt#'monologg/kobert'\n",
        "    \n",
        "    if 'kobert' in pt:\n",
        "        tokenizer = KoBertTokenizer.from_pretrained(pt,  cache_dir='bert_ckpt', do_lower_case=False)\n",
        "        print('load kobert')\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.pt)\n",
        "    \n",
        "    MAX_LEN = args.max_len\n",
        "    train = pd.read_csv('/content/drive/MyDrive/SANUP/1. 실습용자료.txt', sep='|', encoding='cp949')\n",
        "\n",
        "    train = train.fillna(\" \")\n",
        "\n",
        "    train = train[train['digit_1']==\"C\"].copy().reset_index(drop=True)\n",
        "\n",
        "    train['target'] = train['digit_2']\n",
        "    train[\"text\"] = train[\"text_obj\"]+ \" \" + train[\"text_mthd\"] + \" \" + train[\"text_deal\"]\n",
        "\n",
        "    train['text'] = train['text'].str.strip()\n",
        "\n",
        "    train['No.']=train.index\n",
        "\n",
        "    train=train[['text','target']]\n",
        "\n",
        "    input_ids =[]\n",
        "    attention_masks =[]\n",
        "    token_type_ids =[]\n",
        "    train_data_labels = []\n",
        "\n",
        "    for train_sent, train_label in tqdm.tqdm(zip(train['text'], train['target'])):\n",
        "        try:\n",
        "            input_id, attention_mask,_ = bert_tokenizer(train_sent, MAX_LEN=MAX_LEN, tokenizer=tokenizer)\n",
        "\n",
        "            input_ids.append(input_id)\n",
        "            attention_masks.append(attention_mask)\n",
        "            token_type_ids.append(0)\n",
        "            #########################################\n",
        "            train_data_labels.append(train_label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "\n",
        "    train_input_ids=np.array(input_ids, dtype=int)\n",
        "    train_attention_masks=np.array(attention_masks, dtype=int)\n",
        "    train_token_type_ids=np.array(token_type_ids, dtype=int)\n",
        "    ###########################################################\n",
        "    train_inputs=(train_input_ids, train_attention_masks, train_token_type_ids)\n",
        "    train_labels=np.asarray(train_data_labels, dtype=np.int32)\n",
        "\n",
        "    # save\n",
        "    train_data = {}\n",
        "\n",
        "    train_data['input_ids'] = train_input_ids\n",
        "    train_data['attention_mask'] = train_attention_masks\n",
        "    train_data['token_type_ids'] = train_token_type_ids\n",
        "    train_data['targets'] = np.asarray(train_data_labels, dtype=np.int32)\n",
        "    \n",
        "    os.makedirs(f'./data/{pt}/', exist_ok=True)\n",
        "    with open(f'./data/{pt}/train_data_{MAX_LEN}.pickle', 'wb') as f:\n",
        "        pickle.dump(train_data, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def preprocessing_test():\n",
        "    \n",
        "    pt = args.pt\n",
        "    if 'kobert' in pt:\n",
        "        tokenizer = KoBertTokenizer.from_pretrained(pt,  cache_dir='bert_ckpt', do_lower_case=False)\n",
        "        print('load kobert')\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.pt)\n",
        "    MAX_LEN = args.max_len\n",
        "    \n",
        "    test = pd.read_csv('/content/drive/MyDrive/SANUP/2. 모델개발용자료.txt', sep='|', encoding='cp949')\n",
        "\n",
        "    test[\"text\"] = test[\"text_obj\"]+ \" \" + test[\"text_mthd\"] + \" \" + test[\"text_deal\"]\n",
        "\n",
        "    test['text'] = test['text'].str.strip()\n",
        "\n",
        "    test=test[['text']]\n",
        "    \n",
        "    input_ids =[]\n",
        "    attention_masks =[]\n",
        "    token_type_ids =[]\n",
        "\n",
        "    for test_sent in tqdm.tqdm(test['text']):\n",
        "        try:\n",
        "            input_id, attention_mask,_ = bert_tokenizer(test_sent, MAX_LEN=MAX_LEN, tokenizer=tokenizer)\n",
        "\n",
        "            input_ids.append(input_id)\n",
        "            attention_masks.append(attention_mask)\n",
        "            token_type_ids.append(0)\n",
        "            #########################################\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "\n",
        "    test_input_ids=np.array(input_ids, dtype=int)\n",
        "    test_attention_masks=np.array(attention_masks, dtype=int)\n",
        "    test_token_type_ids=np.array(token_type_ids, dtype=int)\n",
        "    ###########################################################\n",
        "    test_inputs=(test_input_ids, test_attention_masks, test_token_type_ids)\n",
        "\n",
        "\n",
        "    # save\n",
        "    test_data = {}\n",
        "\n",
        "    test_data['input_ids'] = test_input_ids\n",
        "    test_data['attention_mask'] = test_attention_masks\n",
        "    test_data['token_type_ids'] = test_token_type_ids\n",
        "    \n",
        "    os.makedirs(f'./data/{pt}/', exist_ok=True)\n",
        "    with open(f'./data/{pt}/test_data_{MAX_LEN}.pickle', 'wb') as f:\n",
        "        pickle.dump(test_data, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "McjHW_XjYxhA"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리\n",
        "# train = train.fillna(\" \")\n",
        "\n",
        "# df = train[train['digit_1']==\"C\"].copy().reset_index(drop=True)\n",
        "\n",
        "# df['target'] = df['digit_2']\n",
        "# df[\"text\"] = df[\"text_obj\"]+ \" \" + df[\"text_mthd\"] + \" \" + df[\"text_deal\"]\n",
        "\n",
        "# df['text'] = df['text'].str.strip()\n",
        "\n",
        "# df['No.']=df.index\n",
        "\n",
        "\n",
        "train = train.fillna(\" \")\n",
        "\n",
        "train = train[train['digit_1']==\"C\"].copy().reset_index(drop=True)\n",
        "\n",
        "train['target'] = train['digit_2']\n",
        "train[\"text\"] = train[\"text_obj\"]+ \" \" + train[\"text_mthd\"] + \" \" + train[\"text_deal\"]\n",
        "\n",
        "train['text'] = train['text'].str.strip()\n",
        "\n",
        "train['No.']=train.index"
      ],
      "metadata": {
        "id": "MM9LdCAvcbPP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_data))"
      ],
      "metadata": {
        "id": "6evaEVwncRaz",
        "outputId": "86bd96f0-a62c-467b-f2de-96ea0cddad34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'title'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-a5834833c821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-b8c80d8230ab>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# get the sentence from the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         encoded_dict = tokenizer(\n\u001b[1;32m      8\u001b[0m           \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;31m# This is an elided recursive call to iloc/loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not applicable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3774\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3776\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'title'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test = test.fillna(\" \")\n",
        "\n",
        "# test = test[test['digit_1']==\"C\"].copy().reset_index(drop=True)\n",
        "\n",
        "# train['target'] = train['digit_2']\n",
        "test[\"text\"] = test[\"text_obj\"]+ \" \" + test[\"text_mthd\"] + \" \" + test[\"text_deal\"]\n",
        "\n",
        "test['text'] = test['text'].str.strip()\n",
        "\n",
        "# test['No.']=train.index"
      ],
      "metadata": {
        "id": "2CqGwm4Hcfii"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "NTP8X0kNcju_",
        "outputId": "41d8a7d9-d2ef-4f46-db92-0ef9cbf8b0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AI_id  digit_1  digit_2  digit_3  text_obj   text_mthd text_deal  \\\n",
              "0      id_000001      NaN      NaN      NaN   치킨전문점에서    고객의주문에의해      치킨판매   \n",
              "1      id_000002      NaN      NaN      NaN      산업공구   다른 소매업자에게    철물 수공구   \n",
              "2      id_000003      NaN      NaN      NaN       절에서    신도을 대상으로    불교단체운영   \n",
              "3      id_000004      NaN      NaN      NaN     영업장에서       고객요구로     자동차튜닝   \n",
              "4      id_000005      NaN      NaN      NaN  실내포장마차에서   접객시설을 갖추고   소주,맥주제공   \n",
              "...          ...      ...      ...      ...       ...         ...       ...   \n",
              "99995  id_099996      NaN      NaN      NaN     사업장에서     일반인대상으로      버섯농장   \n",
              "99996  id_099997      NaN      NaN      NaN     한의원에서     외래환자위주고        치료   \n",
              "99997  id_099998      NaN      NaN      NaN    일반점포에서       소비자에게      그림판매   \n",
              "99998  id_099999      NaN      NaN      NaN     사업장에서  일반인.학생대상으로    학습공간제공   \n",
              "99999  id_100000      NaN      NaN      NaN     사업장에서    대리현대아파트를        관리   \n",
              "\n",
              "                             text  \n",
              "0           치킨전문점에서 고객의주문에의해 치킨판매  \n",
              "1           산업공구 다른 소매업자에게 철물 수공구  \n",
              "2             절에서 신도을 대상으로 불교단체운영  \n",
              "3               영업장에서 고객요구로 자동차튜닝  \n",
              "4      실내포장마차에서 접객시설을 갖추고 소주,맥주제공  \n",
              "...                           ...  \n",
              "99995          사업장에서 일반인대상으로 버섯농장  \n",
              "99996            한의원에서 외래환자위주고 치료  \n",
              "99997           일반점포에서 소비자에게 그림판매  \n",
              "99998     사업장에서 일반인.학생대상으로 학습공간제공  \n",
              "99999           사업장에서 대리현대아파트를 관리  \n",
              "\n",
              "[100000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59f6201d-8db4-4ddd-8933-a28b5664818f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "      <td>치킨전문점에서 고객의주문에의해 치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "      <td>산업공구 다른 소매업자에게 철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "      <td>절에서 신도을 대상으로 불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "      <td>영업장에서 고객요구로 자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "      <td>실내포장마차에서 접객시설을 갖추고 소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "      <td>사업장에서 일반인대상으로 버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "      <td>한의원에서 외래환자위주고 치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "      <td>일반점포에서 소비자에게 그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "      <td>사업장에서 일반인.학생대상으로 학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "      <td>사업장에서 대리현대아파트를 관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59f6201d-8db4-4ddd-8933-a28b5664818f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59f6201d-8db4-4ddd-8933-a28b5664818f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59f6201d-8db4-4ddd-8933-a28b5664818f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for pt, max_len in zip(['monologg/kobert','klue/roberta-base','klue/roberta-small','klue/roberta-large','xlm-roberta-large', \n",
        "           'bert-base-multilingual-uncased', 'klue/roberta-large'],[33,33,33,33,33,33,28]):\n",
        "    args.max_len = max_len\n",
        "    args.pt = pt\n",
        "    preprocessing_train()\n",
        "    # preprocessing_test()\n",
        "        \n",
        "    print(f'{args.pt} 모델 전처리 완료')"
      ],
      "metadata": {
        "id": "VB4L-lQVYzTq",
        "outputId": "d65bd7af-33d7-4d7f-a2ae-933796a5a292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load kobert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "105192it [00:15, 6952.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "monologg/kobert 모델 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105192it [00:10, 10491.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "klue/roberta-base 모델 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105192it [00:09, 10721.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "klue/roberta-small 모델 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105192it [00:09, 10871.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "klue/roberta-large 모델 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105192it [00:10, 10400.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xlm-roberta-large 모델 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105192it [00:12, 8098.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-multilingual-uncased 모델 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "105192it [00:09, 10746.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "klue/roberta-large 모델 전처리 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "4kq1cvWidWvh",
        "outputId": "a3a8c445-7de9-4bc0-c88a-59dc04a52ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             AI_id digit_1  digit_2  digit_3    text_obj    text_mthd  \\\n",
              "0       id_0000001       S       95      952       카센터에서      자동차부분정비   \n",
              "1       id_0000002       G       47      472       상점내에서    일반인을 대상으로   \n",
              "2       id_0000003       G       46      467  절단하여사업체에도매    공업용고무를가지고   \n",
              "3       id_0000004       G       47      475       영업점에서      일반소비자에게   \n",
              "4       id_0000005       Q       87      872        어린이집  보호자의 위탁을 받아   \n",
              "...            ...     ...      ...      ...         ...          ...   \n",
              "999995  id_0999996       C       13      134        제품입고           워싱   \n",
              "999996  id_0999997       F       42      424        현장에서     고객의요청에의해   \n",
              "999997  id_0999998       G       47      474       영업점에서      일반소비자에게   \n",
              "999998  id_0999999       P       85      856       사업장에서    일반고객을대상으로   \n",
              "999999  id_1000000       I       56      561       사업장에서    접객시설을 갖추고   \n",
              "\n",
              "        text_deal  \n",
              "0         타이어오일교환  \n",
              "1         채소.과일판매  \n",
              "2          합성고무도매  \n",
              "3          열쇠잠금장치  \n",
              "4         취학전아동보육  \n",
              "...           ...  \n",
              "999995      청바지워싱  \n",
              "999996     실내인테리어  \n",
              "999997    여성의류 판매  \n",
              "999998       필라테스  \n",
              "999999  한식(미역구)판매  \n",
              "\n",
              "[1000000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbfbf58a-d57d-4e21-be37-a4efb2950abb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_0000001</td>\n",
              "      <td>S</td>\n",
              "      <td>95</td>\n",
              "      <td>952</td>\n",
              "      <td>카센터에서</td>\n",
              "      <td>자동차부분정비</td>\n",
              "      <td>타이어오일교환</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_0000002</td>\n",
              "      <td>G</td>\n",
              "      <td>47</td>\n",
              "      <td>472</td>\n",
              "      <td>상점내에서</td>\n",
              "      <td>일반인을 대상으로</td>\n",
              "      <td>채소.과일판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_0000003</td>\n",
              "      <td>G</td>\n",
              "      <td>46</td>\n",
              "      <td>467</td>\n",
              "      <td>절단하여사업체에도매</td>\n",
              "      <td>공업용고무를가지고</td>\n",
              "      <td>합성고무도매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0000004</td>\n",
              "      <td>G</td>\n",
              "      <td>47</td>\n",
              "      <td>475</td>\n",
              "      <td>영업점에서</td>\n",
              "      <td>일반소비자에게</td>\n",
              "      <td>열쇠잠금장치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_0000005</td>\n",
              "      <td>Q</td>\n",
              "      <td>87</td>\n",
              "      <td>872</td>\n",
              "      <td>어린이집</td>\n",
              "      <td>보호자의 위탁을 받아</td>\n",
              "      <td>취학전아동보육</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>id_0999996</td>\n",
              "      <td>C</td>\n",
              "      <td>13</td>\n",
              "      <td>134</td>\n",
              "      <td>제품입고</td>\n",
              "      <td>워싱</td>\n",
              "      <td>청바지워싱</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>id_0999997</td>\n",
              "      <td>F</td>\n",
              "      <td>42</td>\n",
              "      <td>424</td>\n",
              "      <td>현장에서</td>\n",
              "      <td>고객의요청에의해</td>\n",
              "      <td>실내인테리어</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>id_0999998</td>\n",
              "      <td>G</td>\n",
              "      <td>47</td>\n",
              "      <td>474</td>\n",
              "      <td>영업점에서</td>\n",
              "      <td>일반소비자에게</td>\n",
              "      <td>여성의류 판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999998</th>\n",
              "      <td>id_0999999</td>\n",
              "      <td>P</td>\n",
              "      <td>85</td>\n",
              "      <td>856</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반고객을대상으로</td>\n",
              "      <td>필라테스</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999999</th>\n",
              "      <td>id_1000000</td>\n",
              "      <td>I</td>\n",
              "      <td>56</td>\n",
              "      <td>561</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>한식(미역구)판매</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbfbf58a-d57d-4e21-be37-a4efb2950abb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbfbf58a-d57d-4e21-be37-a4efb2950abb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbfbf58a-d57d-4e21-be37-a4efb2950abb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------\n",
        "#  dataset\n",
        "# ------------------------\n",
        "class KobertDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, data, test=False):\n",
        "        \n",
        "        self.data = data\n",
        "        self.test = test\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.data['input_ids'].shape[0]\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        \n",
        "        ids = torch.tensor(self.data['input_ids'][idx], dtype=torch.long)\n",
        "        mask = torch.tensor(self.data['attention_mask'][idx], dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(self.data['token_type_ids'][idx], dtype=torch.long)\n",
        "         \n",
        "            \n",
        "        if self.test:\n",
        "            return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'token_type_ids': token_type_ids\n",
        "            }\n",
        "        \n",
        "        else:\n",
        "            target = torch.tensor(self.data['targets'][idx],dtype=torch.long)\n",
        "\n",
        "            return {\n",
        "                    'ids': ids,\n",
        "                    'mask': mask,\n",
        "                    'token_type_ids': token_type_ids,\n",
        "                    'targets': target\n",
        "                }"
      ],
      "metadata": {
        "id": "Gnl-YWJeddW1"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------\n",
        "#  scheduler\n",
        "# ------------------------\n",
        "\n",
        "def do_valid(net, valid_loader):\n",
        "\n",
        "    val_loss = 0\n",
        "    target_lst = []\n",
        "    pred_lst = []\n",
        "    logit = []\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    net.eval()\n",
        "    start_timer = timer()\n",
        "    for t, data in enumerate(tqdm.tqdm(valid_loader)):\n",
        "        ids  = data['ids'].to(device)\n",
        "        mask  = data['mask'].to(device)\n",
        "        tokentype = data['token_type_ids'].to(device)\n",
        "        target = data['targets'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if args.amp:\n",
        "                with amp.autocast():\n",
        "                    # output\n",
        "                    output = net(ids, mask)\n",
        "                    output = output[0]\n",
        "\n",
        "                    # loss\n",
        "                    loss = loss_fn(output, target)\n",
        "\n",
        "            else:\n",
        "                output = net(ids, mask)#.squeeze(0)\n",
        "                loss = loss_fn(output, target)\n",
        "            \n",
        "            val_loss += loss\n",
        "            target_lst.extend(target.detach().cpu().numpy())\n",
        "            pred_lst.extend(output.argmax(dim=1).tolist())\n",
        "            logit.extend(output.tolist())\n",
        "            \n",
        "        val_mean_loss = val_loss / len(valid_loader)\n",
        "        validation_score = f1_score(y_true=target_lst, y_pred=pred_lst, average='macro')\n",
        "        validation_acc = accuracy_score(y_true=target_lst, y_pred=pred_lst)\n",
        "        \n",
        "\n",
        "    return val_mean_loss, validation_score, validation_acc, logit\n",
        "\n",
        "def do_predict(net, valid_loader):\n",
        "    \n",
        "    val_loss = 0\n",
        "    pred_lst = []\n",
        "    logit=[]\n",
        "    net.eval()\n",
        "    for t, data in enumerate(tqdm.tqdm(valid_loader)):\n",
        "        ids  = data['ids'].to(device)\n",
        "        mask  = data['mask'].to(device)\n",
        "        tokentype = data['token_type_ids'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if args.amp:\n",
        "                with amp.autocast():\n",
        "                    # output\n",
        "                    output = net(ids, mask)[0]\n",
        "\n",
        "            else:\n",
        "                output = net(ids, mask)\n",
        "             \n",
        "            pred_lst.extend(output.argmax(dim=1).tolist())\n",
        "            logit.extend(output.tolist())\n",
        "            \n",
        "    return pred_lst,logit\n",
        "\n",
        "def run_train(folds=3):\n",
        "    out_dir = args.dir_+ f'/fold{args.fold}/{args.exp_name}/'\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    \n",
        "    # load dataset\n",
        "    train, test = load_data()    \n",
        "    with open(f'./data/{args.pt}/train_data_{args.max_len}.pickle', 'rb') as f:\n",
        "        train_data = pickle.load(f)\n",
        "    with open(f'./data/{args.pt}/test_data_{args.max_len}.pickle', 'rb') as f:\n",
        "        test_data = pickle.load(f)    \n",
        "    \n",
        "    # split fold\n",
        "    for n_fold in range(5):\n",
        "        if n_fold != folds:\n",
        "            print(f'{n_fold} fold pass'+'\\n')\n",
        "            continue\n",
        "            \n",
        "        if args.debug:\n",
        "            train = train.sample(1000).copy()\n",
        "        \n",
        "        trn_idx = train[train['fold']!=n_fold]['id'].values\n",
        "        val_idx = train[train['fold']==n_fold]['id'].values\n",
        "    \n",
        "\n",
        "        train_dict = {'input_ids' : train_data['input_ids'][trn_idx] , 'attention_mask' : train_data['attention_mask'][trn_idx] , \n",
        "                      'token_type_ids' : train_data['token_type_ids'][trn_idx], 'targets' : train_data['targets'][trn_idx]}\n",
        "        val_dict = {'input_ids' : train_data['input_ids'][val_idx] , 'attention_mask' : train_data['attention_mask'][val_idx] , \n",
        "                      'token_type_ids' : train_data['token_type_ids'][val_idx], 'targets' : train_data['targets'][val_idx]}\n",
        "\n",
        "        ## dataset ------------------------------------\n",
        "        train_dataset = KobertDataSet(data = train_dict)\n",
        "        valid_dataset = KobertDataSet(data = val_dict)\n",
        "        trainloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size,\n",
        "                                 num_workers=8, shuffle=True, pin_memory=True)\n",
        "        validloader = DataLoader(dataset=valid_dataset, batch_size=args.batch_size, \n",
        "                                 num_workers=8, shuffle=False, pin_memory=True)\n",
        "\n",
        "        ## net ----------------------------------------\n",
        "        scaler = amp.GradScaler()\n",
        "        if 'xlm-roberta' in args.pt:\n",
        "            net = XLMRobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        \n",
        "        elif 'klue/roberta' in args.pt:\n",
        "            net = RobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        else:\n",
        "            net = BertForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "\n",
        "        net.to(device)\n",
        "        if len(args.gpu)>1:\n",
        "            net = nn.DataParallel(net)\n",
        "\n",
        "        # ------------------------\n",
        "        # loss\n",
        "        # ------------------------\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        # ------------------------\n",
        "        #  Optimizer\n",
        "        # ------------------------\n",
        "        optimizer = optim.Lookahead(optim.RAdam(filter(lambda p: p.requires_grad,net.parameters()), lr=args.start_lr), alpha=0.5, k=5)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = len(trainloader)*args.epochs)\n",
        "        \n",
        "        \n",
        "        # ----\n",
        "        start_timer = timer()\n",
        "        best_score = 0\n",
        "\n",
        "        for epoch in range(1, args.epochs+1):\n",
        "            train_loss = 0\n",
        "            valid_loss = 0\n",
        "\n",
        "            target_lst = []\n",
        "            pred_lst = []\n",
        "            lr = get_learning_rate(optimizer)\n",
        "            print(f'-------------------')\n",
        "            print(f'{epoch}epoch start')\n",
        "            print(f'-------------------'+'\\n')\n",
        "            print(f'learning rate : {lr : .6f}')\n",
        "            for t, data in enumerate(tqdm.tqdm(trainloader)):\n",
        "\n",
        "                # one iteration update  -------------\n",
        "                ids  = data['ids'].to(device)\n",
        "                mask  = data['mask'].to(device)\n",
        "                tokentype = data['token_type_ids'].to(device)\n",
        "                target = data['targets'].to(device)\n",
        "\n",
        "                # ------------\n",
        "                net.train()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                if args.amp:\n",
        "                    with amp.autocast():\n",
        "                        # output\n",
        "                        output = net(ids, mask)\n",
        "                        output = output[0]\n",
        "\n",
        "                        # loss\n",
        "                        loss = loss_fn(output, target)\n",
        "                        train_loss += loss\n",
        "\n",
        "\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "\n",
        "                else:\n",
        "                    # output\n",
        "                    output = net(ids, mask)\n",
        "\n",
        "                    # loss\n",
        "                    loss = loss_fn(output, target)\n",
        "                    train_loss += loss\n",
        "\n",
        "                    # update\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "\n",
        "                # for calculate f1 score\n",
        "                target_lst.extend(target.detach().cpu().numpy())\n",
        "                pred_lst.extend(output.argmax(dim=1).tolist())\n",
        "\n",
        "\n",
        "                if scheduler is not None:\n",
        "                    scheduler.step() \n",
        "            train_loss = train_loss / len(trainloader)\n",
        "            train_score = f1_score(y_true=target_lst, y_pred=pred_lst, average='macro')\n",
        "            train_acc = accuracy_score(y_true=target_lst, y_pred=pred_lst)\n",
        "\n",
        "            # validation\n",
        "            valid_loss, valid_score, valid_acc, _ = do_valid(net, validloader)\n",
        "\n",
        "\n",
        "            if valid_acc > best_score:\n",
        "                best_score = valid_acc\n",
        "                best_epoch = epoch\n",
        "                best_loss = valid_loss\n",
        "\n",
        "                torch.save(net.state_dict(), out_dir + f'/{folds}f_{epoch}e_{best_score:.4f}_s.pth')\n",
        "                print('best model saved'+'\\n')\n",
        "\n",
        "\n",
        "            print(f'train loss : {train_loss:.4f}, train f1 score : {train_score : .4f}, train acc : {train_acc : .4f}'+'\\n')\n",
        "            print(f'valid loss : {valid_loss:.4f}, valid f1 score : {valid_score : .4f}, valid acc : {valid_acc : .4f}'+'\\n')\n",
        "\n",
        "\n",
        "        print(f'best valid loss : {best_loss : .4f}'+'\\n')\n",
        "        print(f'best epoch : {best_epoch }'+'\\n')\n",
        "        print(f'best accuracy : {best_score : .4f}'+'\\n')\n",
        "        \n",
        "def run_predict(model_path):\n",
        "    ## dataset ------------------------------------\n",
        "    # load\n",
        "    with open(f'./data/{args.pt}/test_data_{args.max_len}.pickle', 'rb') as f:\n",
        "        test_dict = pickle.load(f)\n",
        "        \n",
        "    print('test load')\n",
        "    test_dataset = KobertDataSet(data = test_dict, test=True)\n",
        "    testloader = DataLoader(dataset=test_dataset, batch_size=args.batch_size, \n",
        "                             num_workers=8, shuffle=False, pin_memory=True)\n",
        "    print('set testloader')\n",
        "    ## net ----------------------------------------\n",
        "    scaler = amp.GradScaler()\n",
        "    if 'xlm-roberta' in args.pt:\n",
        "        net = XLMRobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        \n",
        "    elif 'klue/roberta' in args.pt:\n",
        "        net = RobertaForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "    else:\n",
        "        net = BertForSequenceClassification.from_pretrained(args.pt, num_labels = 7) \n",
        "        \n",
        "    net.to(device)\n",
        "    \n",
        "    if len(args.gpu)>1:\n",
        "        net = nn.DataParallel(net)\n",
        "\n",
        "    f = torch.load(model_path)\n",
        "    net.load_state_dict(f, strict=True)  # True\n",
        "    print('load saved models')\n",
        "    # ------------------------\n",
        "    # validation\n",
        "    preds, logit = do_predict(net, testloader) #outputs\n",
        "           \n",
        "    print('complete predict')\n",
        "    \n",
        "    return preds, np.array(logit)\n",
        "     "
      ],
      "metadata": {
        "id": "4b9D2_RXdjeV"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"5fold 전용\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    for pt, max_len in zip(['monologg/kobert','klue/roberta-base','klue/roberta-small','klue/roberta-large','xlm-roberta-large', \n",
        "           'bert-base-multilingual-uncased', 'klue/roberta-large'],[33,33,33,33,33,33,28]):\n",
        "        \n",
        "        args.max_len = max_len\n",
        "        args.pt = pt\n",
        "        args.exp_name = str(args.pt) + '_' + str(args.max_len)\n",
        "        \n",
        "        for i in [0,1,2,3,4]: # 5fold\n",
        "            run_train(folds=i)"
      ],
      "metadata": {
        "id": "iqUR07Uqdk6p",
        "outputId": "1961ea81-0ccc-4e92-d12f-556d1502081e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-eefd223610dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 5fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-6fc4076bb1f5>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(folds)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./data/{args.pt}/train_data_{args.max_len}.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-68a6bb5f01e2>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['text', 'target'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble():\n",
        "    final_logit=0\n",
        "    args.max_len=33\n",
        "    args.pt = 'monologg/kobert'\n",
        "    _, logit1 = run_predict(\"./saved_models/fold3/kobert/0f_9e_0.8895_s.pth\")\n",
        "    _, logit2 = run_predict(\"./saved_models/fold3/kobert/1f_10e_0.8823_s.pth\")\n",
        "    _, logit3 = run_predict(\"./saved_models/fold3/kobert/2f_8e_0.8888_s.pth\")\n",
        "    _, logit4 = run_predict(\"./saved_models/fold3/kobert/3f_10e_0.8897_s.pth\")\n",
        "    _, logit5 = run_predict(\"./saved_models/fold3/kobert/4f_8e_0.8867_s.pth\")\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "    \n",
        "    #####################\n",
        "\n",
        "    args.pt = 'klue/roberta-base'\n",
        "    _, logit1 = run_predict(\"./saved_models/fold3/roberta-base/0f_5e_0.8920_s.pth\")\n",
        "    _, logit2 = run_predict(\"./saved_models/fold3/roberta-base/1f_4e_0.8879_s.pth\")\n",
        "    _, logit3 = run_predict(\"./saved_models/fold3/roberta-base/2f_5e_0.8889_s.pth\")\n",
        "    _, logit4 = run_predict(\"./saved_models/fold3/roberta-base/3f_4e_0.8951_s.pth\")\n",
        "    _, logit5 = run_predict(\"./saved_models/fold3/roberta-base/4f_4e_0.8887_s.pth\")\n",
        "\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "\n",
        "    #####################\n",
        "    args.pt = 'klue/roberta-small'\n",
        "    preds1, logit1 = run_predict(\"./saved_models/fold3/roberta-small/0f_8e_0.8900_s.pth\")\n",
        "    preds2, logit2 = run_predict(\"./saved_models/fold3/roberta-small/1f_9e_0.8813_s.pth\")\n",
        "    preds3, logit3 = run_predict(\"./saved_models/fold3/roberta-small/2f_7e_0.8884_s.pth\")\n",
        "    preds4, logit4 = run_predict(\"./saved_models/fold3/roberta-small/3f_3e_0.8958_s.pth\")\n",
        "    preds5, logit5 = run_predict(\"./saved_models/fold3/roberta-small/4f_4e_0.8881_s.pth\") # 8884 가능\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "    #####################\n",
        "\n",
        "    args.pt = 'bert-base-multilingual-uncased'\n",
        "    preds1, logit1 = run_predict(\"./saved_models/fold3/bert-base-multilingual-uncased/0f_5e_0.8624_s.pth\")\n",
        "    preds2, logit2 = run_predict(\"./saved_models/fold3/bert-base-multilingual-uncased/1f_8e_0.8573_s.pth\")\n",
        "    preds3, logit3 = run_predict(\"./saved_models/fold3/bert-base-multilingual-uncased/2f_9e_0.8674_s.pth\")\n",
        "    preds4, logit4 = run_predict(\"./saved_models/fold3/bert-base-multilingual-uncased/3f_8e_0.8649_s.pth\")\n",
        "    preds5, logit5 = run_predict(\"./saved_models/fold3/bert-base-multilingual-uncased/4f_9e_0.8673_s.pth\")\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "    #####################\n",
        "    args.pt = 'klue/roberta-large'\n",
        "    preds1, logit1 = run_predict(\"./saved_models/fold3/klue-roberta-large/0f_2e_0.8905_s.pth\")\n",
        "    preds2, logit2 = run_predict(\"./saved_models/fold3/klue-roberta-large/1f_4e_0.8897_s.pth\")\n",
        "    preds3, logit3 = run_predict(\"./saved_models/fold3/klue-roberta-large/2f_3e_0.8887_s.pth\")\n",
        "    preds4, logit4 = run_predict(\"./saved_models/fold3/klue-roberta-large/3f_3e_0.8949_s.pth\")\n",
        "    preds5, logit5 = run_predict(\"./saved_models/fold3/klue-roberta-large/4f_2e_0.8939_s.pth\")\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "    #####################\n",
        "    args.pt = 'xlm-roberta-large'\n",
        "    preds1, logit1 = run_predict(\"./saved_models/fold3/xlm-roberta-large_radam/0f_6e_0.8928_s.pth\")\n",
        "    preds2, logit2 = run_predict(\"./saved_models/fold3/xlm-roberta-large_radam/1f_5e_0.8850_s.pth\")\n",
        "    preds3, logit3 = run_predict(\"./saved_models/fold3/xlm-roberta-large_radam/2f_5e_0.8891_s.pth\")\n",
        "    preds4, logit4 = run_predict(\"./saved_models/fold3/xlm-roberta-large_radam/3f_8e_0.8938_s.pth\")\n",
        "    preds5, logit5 = run_predict(\"./saved_models/fold3/xlm-roberta-large_radam/4f_6e_0.8911_s.pth\")\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "    #####################\n",
        "    args.max_len=28\n",
        "    args.pt = 'klue/roberta-large'\n",
        "    preds1, logit1 = run_predict(\"./saved_models/fold3/klue-roberta-large_28/0f_6e_0.8912_s.pth\")\n",
        "    preds2, logit2 = run_predict(\"./saved_models/fold3//klue-roberta-large_28/1f_3e_0.8891_s.pth\")\n",
        "    preds3, logit3 = run_predict(\"./saved_models/fold3//klue-roberta-large_28/2f_5e_0.8891_s.pth\")\n",
        "    preds4, logit4 = run_predict(\"./saved_models/fold3//klue-roberta-large_28/3f_4e_0.8961_s.pth\")\n",
        "    preds5, logit5 = run_predict(\"./saved_models/fold3//klue-roberta-large_28/4f_2e_0.8938_s.pth\")\n",
        "    final_logit += (logit1+logit2+logit3+logit4+logit5)/5\n",
        "    \n",
        "    return final_logit"
      ],
      "metadata": {
        "id": "RSVqoRcKdo_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_logit = ensemble()"
      ],
      "metadata": {
        "id": "9WqO7PCydqb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['input_ids', 'token_type_ids', 'attention_mask']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kaq5oftbKrjc",
        "outputId": "3b7c721b-dbf7-4bb8-c645-70d571848ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           input_ids  \\\n",
              "0  [2, 4473, 4067, 6515, 54, 7003, 7225, 4635, 77...   \n",
              "1  [2, 517, 6756, 7088, 768, 517, 5330, 5452, 781...   \n",
              "2  [2, 517, 6202, 7483, 3838, 46, 517, 5330, 5452...   \n",
              "3  [2, 517, 6756, 7088, 5330, 7321, 517, 5330, 60...   \n",
              "4  [2, 993, 6228, 4067, 5788, 5330, 5452, 754, 75...   \n",
              "\n",
              "                                      token_type_ids  \\\n",
              "0         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "1         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "2                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                      attention_mask  \n",
              "0         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "1         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "2                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-934b69e6-e05b-44f4-84dc-dc5b643155c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_ids</th>\n",
              "      <th>token_type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2, 4473, 4067, 6515, 54, 7003, 7225, 4635, 77...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 517, 6756, 7088, 768, 517, 5330, 5452, 781...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2, 517, 6202, 7483, 3838, 46, 517, 5330, 5452...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2, 517, 6756, 7088, 5330, 7321, 517, 5330, 60...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 993, 6228, 4067, 5788, 5330, 5452, 754, 75...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-934b69e6-e05b-44f4-84dc-dc5b643155c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-934b69e6-e05b-44f4-84dc-dc5b643155c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-934b69e6-e05b-44f4-84dc-dc5b643155c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## GPU\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "x-2-y9jELcGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSNp5sngLd40",
        "outputId": "34e555f8-9cd4-4c56-96ee-71b3b452a705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = {}\n",
        "for i in range(len(df['target'].unique())):\n",
        "  my_dict[df['target'].unique()[i]] = i"
      ],
      "metadata": {
        "id": "tAdpc1F1Le-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSMryc2ZLgYP",
        "outputId": "6bd81f53-1fda-4486-e186-d206b687d29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 1,\n",
              " 11: 19,\n",
              " 12: 24,\n",
              " 13: 17,\n",
              " 14: 5,\n",
              " 15: 16,\n",
              " 16: 11,\n",
              " 17: 18,\n",
              " 18: 14,\n",
              " 19: 23,\n",
              " 20: 8,\n",
              " 21: 22,\n",
              " 22: 2,\n",
              " 23: 15,\n",
              " 24: 12,\n",
              " 25: 3,\n",
              " 26: 10,\n",
              " 27: 21,\n",
              " 28: 7,\n",
              " 29: 0,\n",
              " 30: 20,\n",
              " 31: 13,\n",
              " 32: 4,\n",
              " 33: 6,\n",
              " 34: 9}"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def target_to_label(text:str):\n",
        "  return my_dict[text]\n",
        "\n",
        "df['target_label'] = df['target'].map(target_to_label)"
      ],
      "metadata": {
        "id": "ln7s2WbIL2Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "l00wG6eyMX2U",
        "outputId": "505a4af2-a0a4-42cd-e83d-53898bd32998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             AI_id digit_1  digit_2  digit_3    text_obj       text_mthd  \\\n",
              "0       id_0000006       C       29      291           철           절삭.용접   \n",
              "1       id_0000008       C       10      107      쌀을 가지고            가공하여   \n",
              "2       id_0000011       C       10      102          멸치          입고, 가공   \n",
              "3       id_0000021       C       10      107       쌀을가지고  가루로 분쇄하여 떡을 쪄서   \n",
              "4       id_0000027       C       22      221          고무            절단가공   \n",
              "...            ...     ...      ...      ...         ...             ...   \n",
              "105187  id_0999971       C       28      281  트랜스,다이오드,칩              조립   \n",
              "105188  id_0999976       C       25      259       기타임가공                   \n",
              "105189  id_0999986       C       10      106      벼를 가지고         벼를 도정하여   \n",
              "105190  id_0999994       C       32      320  카본열선,퀼팅구조체      조립.배열.봉제하여   \n",
              "105191  id_0999996       C       13      134        제품입고              워싱   \n",
              "\n",
              "             text_deal  target                              text     No.  \\\n",
              "0              카프라배관자재      29                   철 절삭.용접 카프라배관자재       0   \n",
              "1                  떡제조      10                   쌀을 가지고 가공하여 떡제조       1   \n",
              "2                           10                         멸치 입고, 가공       2   \n",
              "3          백설기 꿀떡 절편판매      10  쌀을가지고 가루로 분쇄하여 떡을 쪄서 백설기 꿀떡 절편판매       3   \n",
              "4           가스켓,다이아후레임      22                고무 절단가공 가스켓,다이아후레임       4   \n",
              "...                ...     ...                               ...     ...   \n",
              "105187  전원공급장치(파워써플라이)      28      트랜스,다이오드,칩 조립 전원공급장치(파워써플라이)  105187   \n",
              "105188                      25                             기타임가공  105188   \n",
              "105189        소비자에게 판매      10           벼를 가지고 벼를 도정하여 소비자에게 판매  105189   \n",
              "105190         의료용매트리스      32     카본열선,퀼팅구조체 조립.배열.봉제하여 의료용매트리스  105190   \n",
              "105191           청바지워싱      13                     제품입고 워싱 청바지워싱  105191   \n",
              "\n",
              "                                                input_ids  \\\n",
              "0       [2, 4473, 4067, 6515, 54, 7003, 7225, 4635, 77...   \n",
              "1       [2, 517, 6756, 7088, 768, 517, 5330, 5452, 781...   \n",
              "2       [2, 517, 6202, 7483, 3838, 46, 517, 5330, 5452...   \n",
              "3       [2, 517, 6756, 7088, 5330, 7321, 517, 5330, 60...   \n",
              "4       [2, 993, 6228, 4067, 5788, 5330, 5452, 754, 75...   \n",
              "...                                                   ...   \n",
              "105187  [2, 4773, 6025, 6664, 46, 5782, 7096, 6964, 59...   \n",
              "105188                     [2, 1258, 7586, 5330, 5452, 3]   \n",
              "105189  [2, 517, 6353, 6116, 768, 517, 6353, 6116, 517...   \n",
              "105190  [2, 4635, 6383, 6940, 6559, 46, 0, 7681, 5501,...   \n",
              "105191  [2, 4158, 7138, 5439, 3530, 6750, 4483, 6273, ...   \n",
              "\n",
              "                                           token_type_ids  \\\n",
              "0              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "1              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "2                          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "...                                                   ...   \n",
              "105187  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "105188                                 [0, 0, 0, 0, 0, 0]   \n",
              "105189   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "105190  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "105191               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "\n",
              "                                           attention_mask  target_label  \n",
              "0              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             0  \n",
              "1              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             1  \n",
              "2                          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             1  \n",
              "3       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             1  \n",
              "4       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             2  \n",
              "...                                                   ...           ...  \n",
              "105187  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             7  \n",
              "105188                                 [1, 1, 1, 1, 1, 1]             3  \n",
              "105189   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             1  \n",
              "105190  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             4  \n",
              "105191               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]            17  \n",
              "\n",
              "[105192 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2e8c00b-13cf-4ebc-a1a2-7aba2342021a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>No.</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>token_type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>target_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_0000006</td>\n",
              "      <td>C</td>\n",
              "      <td>29</td>\n",
              "      <td>291</td>\n",
              "      <td>철</td>\n",
              "      <td>절삭.용접</td>\n",
              "      <td>카프라배관자재</td>\n",
              "      <td>29</td>\n",
              "      <td>철 절삭.용접 카프라배관자재</td>\n",
              "      <td>0</td>\n",
              "      <td>[2, 4473, 4067, 6515, 54, 7003, 7225, 4635, 77...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_0000008</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>107</td>\n",
              "      <td>쌀을 가지고</td>\n",
              "      <td>가공하여</td>\n",
              "      <td>떡제조</td>\n",
              "      <td>10</td>\n",
              "      <td>쌀을 가지고 가공하여 떡제조</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 517, 6756, 7088, 768, 517, 5330, 5452, 781...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_0000011</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>102</td>\n",
              "      <td>멸치</td>\n",
              "      <td>입고, 가공</td>\n",
              "      <td></td>\n",
              "      <td>10</td>\n",
              "      <td>멸치 입고, 가공</td>\n",
              "      <td>2</td>\n",
              "      <td>[2, 517, 6202, 7483, 3838, 46, 517, 5330, 5452...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0000021</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>107</td>\n",
              "      <td>쌀을가지고</td>\n",
              "      <td>가루로 분쇄하여 떡을 쪄서</td>\n",
              "      <td>백설기 꿀떡 절편판매</td>\n",
              "      <td>10</td>\n",
              "      <td>쌀을가지고 가루로 분쇄하여 떡을 쪄서 백설기 꿀떡 절편판매</td>\n",
              "      <td>3</td>\n",
              "      <td>[2, 517, 6756, 7088, 5330, 7321, 517, 5330, 60...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_0000027</td>\n",
              "      <td>C</td>\n",
              "      <td>22</td>\n",
              "      <td>221</td>\n",
              "      <td>고무</td>\n",
              "      <td>절단가공</td>\n",
              "      <td>가스켓,다이아후레임</td>\n",
              "      <td>22</td>\n",
              "      <td>고무 절단가공 가스켓,다이아후레임</td>\n",
              "      <td>4</td>\n",
              "      <td>[2, 993, 6228, 4067, 5788, 5330, 5452, 754, 75...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105187</th>\n",
              "      <td>id_0999971</td>\n",
              "      <td>C</td>\n",
              "      <td>28</td>\n",
              "      <td>281</td>\n",
              "      <td>트랜스,다이오드,칩</td>\n",
              "      <td>조립</td>\n",
              "      <td>전원공급장치(파워써플라이)</td>\n",
              "      <td>28</td>\n",
              "      <td>트랜스,다이오드,칩 조립 전원공급장치(파워써플라이)</td>\n",
              "      <td>105187</td>\n",
              "      <td>[2, 4773, 6025, 6664, 46, 5782, 7096, 6964, 59...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105188</th>\n",
              "      <td>id_0999976</td>\n",
              "      <td>C</td>\n",
              "      <td>25</td>\n",
              "      <td>259</td>\n",
              "      <td>기타임가공</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>25</td>\n",
              "      <td>기타임가공</td>\n",
              "      <td>105188</td>\n",
              "      <td>[2, 1258, 7586, 5330, 5452, 3]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105189</th>\n",
              "      <td>id_0999986</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>106</td>\n",
              "      <td>벼를 가지고</td>\n",
              "      <td>벼를 도정하여</td>\n",
              "      <td>소비자에게 판매</td>\n",
              "      <td>10</td>\n",
              "      <td>벼를 가지고 벼를 도정하여 소비자에게 판매</td>\n",
              "      <td>105189</td>\n",
              "      <td>[2, 517, 6353, 6116, 768, 517, 6353, 6116, 517...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105190</th>\n",
              "      <td>id_0999994</td>\n",
              "      <td>C</td>\n",
              "      <td>32</td>\n",
              "      <td>320</td>\n",
              "      <td>카본열선,퀼팅구조체</td>\n",
              "      <td>조립.배열.봉제하여</td>\n",
              "      <td>의료용매트리스</td>\n",
              "      <td>32</td>\n",
              "      <td>카본열선,퀼팅구조체 조립.배열.봉제하여 의료용매트리스</td>\n",
              "      <td>105190</td>\n",
              "      <td>[2, 4635, 6383, 6940, 6559, 46, 0, 7681, 5501,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105191</th>\n",
              "      <td>id_0999996</td>\n",
              "      <td>C</td>\n",
              "      <td>13</td>\n",
              "      <td>134</td>\n",
              "      <td>제품입고</td>\n",
              "      <td>워싱</td>\n",
              "      <td>청바지워싱</td>\n",
              "      <td>13</td>\n",
              "      <td>제품입고 워싱 청바지워싱</td>\n",
              "      <td>105191</td>\n",
              "      <td>[2, 4158, 7138, 5439, 3530, 6750, 4483, 6273, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105192 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e8c00b-13cf-4ebc-a1a2-7aba2342021a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2e8c00b-13cf-4ebc-a1a2-7aba2342021a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2e8c00b-13cf-4ebc-a1a2-7aba2342021a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['target', 'target_label']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qZeL2Q2YMHpf",
        "outputId": "f1f4588c-3971-46e1-9399-03516e026b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target  target_label\n",
              "0      29             0\n",
              "1      10             1\n",
              "2      10             1\n",
              "3      10             1\n",
              "4      22             2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7836efb0-c85f-4813-8f74-97267c5e0492\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>target_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7836efb0-c85f-4813-8f74-97267c5e0492')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7836efb0-c85f-4813-8f74-97267c5e0492 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7836efb0-c85f-4813-8f74-97267c5e0492');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "bj5DjhwbMI5x",
        "outputId": "d570e4e6-ab9e-4344-e895-bb9781688cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             AI_id digit_1  digit_2  digit_3    text_obj       text_mthd  \\\n",
              "0       id_0000006       C       29      291           철           절삭.용접   \n",
              "1       id_0000008       C       10      107      쌀을 가지고            가공하여   \n",
              "2       id_0000011       C       10      102          멸치          입고, 가공   \n",
              "3       id_0000021       C       10      107       쌀을가지고  가루로 분쇄하여 떡을 쪄서   \n",
              "4       id_0000027       C       22      221          고무            절단가공   \n",
              "...            ...     ...      ...      ...         ...             ...   \n",
              "105187  id_0999971       C       28      281  트랜스,다이오드,칩              조립   \n",
              "105188  id_0999976       C       25      259       기타임가공                   \n",
              "105189  id_0999986       C       10      106      벼를 가지고         벼를 도정하여   \n",
              "105190  id_0999994       C       32      320  카본열선,퀼팅구조체      조립.배열.봉제하여   \n",
              "105191  id_0999996       C       13      134        제품입고              워싱   \n",
              "\n",
              "             text_deal  target                              text     No.  \\\n",
              "0              카프라배관자재      29                   철 절삭.용접 카프라배관자재       0   \n",
              "1                  떡제조      10                   쌀을 가지고 가공하여 떡제조       1   \n",
              "2                           10                         멸치 입고, 가공       2   \n",
              "3          백설기 꿀떡 절편판매      10  쌀을가지고 가루로 분쇄하여 떡을 쪄서 백설기 꿀떡 절편판매       3   \n",
              "4           가스켓,다이아후레임      22                고무 절단가공 가스켓,다이아후레임       4   \n",
              "...                ...     ...                               ...     ...   \n",
              "105187  전원공급장치(파워써플라이)      28      트랜스,다이오드,칩 조립 전원공급장치(파워써플라이)  105187   \n",
              "105188                      25                             기타임가공  105188   \n",
              "105189        소비자에게 판매      10           벼를 가지고 벼를 도정하여 소비자에게 판매  105189   \n",
              "105190         의료용매트리스      32     카본열선,퀼팅구조체 조립.배열.봉제하여 의료용매트리스  105190   \n",
              "105191           청바지워싱      13                     제품입고 워싱 청바지워싱  105191   \n",
              "\n",
              "                                                input_ids  \\\n",
              "0       [2, 4473, 4067, 6515, 54, 7003, 7225, 4635, 77...   \n",
              "1       [2, 517, 6756, 7088, 768, 517, 5330, 5452, 781...   \n",
              "2       [2, 517, 6202, 7483, 3838, 46, 517, 5330, 5452...   \n",
              "3       [2, 517, 6756, 7088, 5330, 7321, 517, 5330, 60...   \n",
              "4       [2, 993, 6228, 4067, 5788, 5330, 5452, 754, 75...   \n",
              "...                                                   ...   \n",
              "105187  [2, 4773, 6025, 6664, 46, 5782, 7096, 6964, 59...   \n",
              "105188                     [2, 1258, 7586, 5330, 5452, 3]   \n",
              "105189  [2, 517, 6353, 6116, 768, 517, 6353, 6116, 517...   \n",
              "105190  [2, 4635, 6383, 6940, 6559, 46, 0, 7681, 5501,...   \n",
              "105191  [2, 4158, 7138, 5439, 3530, 6750, 4483, 6273, ...   \n",
              "\n",
              "                                           token_type_ids  \\\n",
              "0              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "1              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "2                          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "...                                                   ...   \n",
              "105187  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "105188                                 [0, 0, 0, 0, 0, 0]   \n",
              "105189   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "105190  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "105191               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "\n",
              "                                           attention_mask  target_label  \n",
              "0              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             0  \n",
              "1              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             1  \n",
              "2                          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             1  \n",
              "3       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             1  \n",
              "4       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             2  \n",
              "...                                                   ...           ...  \n",
              "105187  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             7  \n",
              "105188                                 [1, 1, 1, 1, 1, 1]             3  \n",
              "105189   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             1  \n",
              "105190  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...             4  \n",
              "105191               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]            17  \n",
              "\n",
              "[105192 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d184fd1c-5a8f-4c63-8ba5-60f73919300e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>No.</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>token_type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>target_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_0000006</td>\n",
              "      <td>C</td>\n",
              "      <td>29</td>\n",
              "      <td>291</td>\n",
              "      <td>철</td>\n",
              "      <td>절삭.용접</td>\n",
              "      <td>카프라배관자재</td>\n",
              "      <td>29</td>\n",
              "      <td>철 절삭.용접 카프라배관자재</td>\n",
              "      <td>0</td>\n",
              "      <td>[2, 4473, 4067, 6515, 54, 7003, 7225, 4635, 77...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_0000008</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>107</td>\n",
              "      <td>쌀을 가지고</td>\n",
              "      <td>가공하여</td>\n",
              "      <td>떡제조</td>\n",
              "      <td>10</td>\n",
              "      <td>쌀을 가지고 가공하여 떡제조</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 517, 6756, 7088, 768, 517, 5330, 5452, 781...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_0000011</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>102</td>\n",
              "      <td>멸치</td>\n",
              "      <td>입고, 가공</td>\n",
              "      <td></td>\n",
              "      <td>10</td>\n",
              "      <td>멸치 입고, 가공</td>\n",
              "      <td>2</td>\n",
              "      <td>[2, 517, 6202, 7483, 3838, 46, 517, 5330, 5452...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0000021</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>107</td>\n",
              "      <td>쌀을가지고</td>\n",
              "      <td>가루로 분쇄하여 떡을 쪄서</td>\n",
              "      <td>백설기 꿀떡 절편판매</td>\n",
              "      <td>10</td>\n",
              "      <td>쌀을가지고 가루로 분쇄하여 떡을 쪄서 백설기 꿀떡 절편판매</td>\n",
              "      <td>3</td>\n",
              "      <td>[2, 517, 6756, 7088, 5330, 7321, 517, 5330, 60...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_0000027</td>\n",
              "      <td>C</td>\n",
              "      <td>22</td>\n",
              "      <td>221</td>\n",
              "      <td>고무</td>\n",
              "      <td>절단가공</td>\n",
              "      <td>가스켓,다이아후레임</td>\n",
              "      <td>22</td>\n",
              "      <td>고무 절단가공 가스켓,다이아후레임</td>\n",
              "      <td>4</td>\n",
              "      <td>[2, 993, 6228, 4067, 5788, 5330, 5452, 754, 75...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105187</th>\n",
              "      <td>id_0999971</td>\n",
              "      <td>C</td>\n",
              "      <td>28</td>\n",
              "      <td>281</td>\n",
              "      <td>트랜스,다이오드,칩</td>\n",
              "      <td>조립</td>\n",
              "      <td>전원공급장치(파워써플라이)</td>\n",
              "      <td>28</td>\n",
              "      <td>트랜스,다이오드,칩 조립 전원공급장치(파워써플라이)</td>\n",
              "      <td>105187</td>\n",
              "      <td>[2, 4773, 6025, 6664, 46, 5782, 7096, 6964, 59...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105188</th>\n",
              "      <td>id_0999976</td>\n",
              "      <td>C</td>\n",
              "      <td>25</td>\n",
              "      <td>259</td>\n",
              "      <td>기타임가공</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>25</td>\n",
              "      <td>기타임가공</td>\n",
              "      <td>105188</td>\n",
              "      <td>[2, 1258, 7586, 5330, 5452, 3]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105189</th>\n",
              "      <td>id_0999986</td>\n",
              "      <td>C</td>\n",
              "      <td>10</td>\n",
              "      <td>106</td>\n",
              "      <td>벼를 가지고</td>\n",
              "      <td>벼를 도정하여</td>\n",
              "      <td>소비자에게 판매</td>\n",
              "      <td>10</td>\n",
              "      <td>벼를 가지고 벼를 도정하여 소비자에게 판매</td>\n",
              "      <td>105189</td>\n",
              "      <td>[2, 517, 6353, 6116, 768, 517, 6353, 6116, 517...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105190</th>\n",
              "      <td>id_0999994</td>\n",
              "      <td>C</td>\n",
              "      <td>32</td>\n",
              "      <td>320</td>\n",
              "      <td>카본열선,퀼팅구조체</td>\n",
              "      <td>조립.배열.봉제하여</td>\n",
              "      <td>의료용매트리스</td>\n",
              "      <td>32</td>\n",
              "      <td>카본열선,퀼팅구조체 조립.배열.봉제하여 의료용매트리스</td>\n",
              "      <td>105190</td>\n",
              "      <td>[2, 4635, 6383, 6940, 6559, 46, 0, 7681, 5501,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105191</th>\n",
              "      <td>id_0999996</td>\n",
              "      <td>C</td>\n",
              "      <td>13</td>\n",
              "      <td>134</td>\n",
              "      <td>제품입고</td>\n",
              "      <td>워싱</td>\n",
              "      <td>청바지워싱</td>\n",
              "      <td>13</td>\n",
              "      <td>제품입고 워싱 청바지워싱</td>\n",
              "      <td>105191</td>\n",
              "      <td>[2, 4158, 7138, 5439, 3530, 6750, 4483, 6273, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105192 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d184fd1c-5a8f-4c63-8ba5-60f73919300e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d184fd1c-5a8f-4c63-8ba5-60f73919300e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d184fd1c-5a8f-4c63-8ba5-60f73919300e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_train = df[['No.', 'text', 'target_label']][:int(len(df)*0.8)]\n",
        "# dataset_test = df[['No.', 'text', 'target_label']][int(len(df)*0.8):]\n",
        "dataset_train, dataset_test = train_test_split(df[['No.', 'text', 'target_label']], test_size=0.2, random_state=42, shuffle=True)\n",
        "dataset_train.to_csv('dataset_train.txt', index=False, header=True, sep='\\t', encoding='utf8')\n",
        "dataset_test.to_csv('dataset_test.txt', index=False, header=True, sep='\\t', encoding='utf8')"
      ],
      "metadata": {
        "id": "Cq8W91jSMK09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = nlp.data.TSVDataset('/content/dataset_train.txt', field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset('/content/dataset_test.txt', field_indices=[1,2], num_discard_samples=1)"
      ],
      "metadata": {
        "id": "TcPUfX7SMMtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQb3OHdeMOHc",
        "outputId": "345e7aee-9b16-4d79-b66b-256cd3b6cb3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "KMwJvMuYMP_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Setting parameters\n",
        "max_len = 256\n",
        "batch_size = 8\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 20\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "lwCDnzlvMROd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "id": "X3jj7dMwMSo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(data_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG577jWAMT3W",
        "outputId": "9c05b6e7-c1c4-4a2c-b53f-c6c08fadfaf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   2, 4213, 6241,  517,   46,  517,  441,  389,  391, 4213, 6241,\n",
              "         517,   46, 1260, 5330, 5462, 6141,    3,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1], dtype=int32),\n",
              " array(18, dtype=int32),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=4)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNfQF3N2MU-O",
        "outputId": "74b41adc-7551-4fca-f4c1-71c1c3c37c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['target_label'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU5iDKiCM1bA",
        "outputId": "08a38566-f6bb-4eb7-ace0-564a57b8111b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=520,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "Q9BFiRfYM2ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ],
      "metadata": {
        "id": "yPy4KGH-M446"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "metadata": {
        "id": "L-vMlr1mM6PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAGpdJ43M7xW",
        "outputId": "9edfcb61-7d40-4c33-cc11-bbeebab7ffda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ],
      "metadata": {
        "id": "tdrA2a8RM8_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "metadata": {
        "id": "cbnA7qG0M-OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "SoM9z-8sM_nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "    # torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "idONFnM7NA1Y",
        "outputId": "d1a394b8-af7a-40af-f3a0-09a22a5aad96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-165-64c337b7a74c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-158-d2d412cd7a60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     ):\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "woPj3J26NCqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6ckEjNj0TZDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}